---
author: v-demjoh
ms.service: cognitive-services
ms.topic: include
ms.date: 9/22/2020
ms.author: v-demjoh
ms.openlocfilehash: 8eb74d13c15be619512376da326a94876563f898
ms.sourcegitcommit: 6a4687b86b7aabaeb6aacdfa6c2a1229073254de
ms.translationtype: HT
ms.contentlocale: pt-BR
ms.lasthandoff: 10/06/2020
ms.locfileid: "91761611"
---
Você pode transcrever uma fala em texto usando o SDK de Fala para Swift e Objective-C.

## <a name="prerequisites"></a>Pré-requisitos

Os exemplos a seguir pressupõem que você tenha uma conta do Azure e uma assinatura do serviço de Fala. Se você não tiver uma conta e uma assinatura, [experimente o serviço de Fala gratuitamente](../../../overview.md#try-the-speech-service-for-free).

## <a name="install-speech-sdk-and-samples"></a>Instalar o SDK de Fala e exemplos

O [SDK de Fala dos Serviços Cognitivos](https://github.com/Azure-Samples/cognitive-services-speech-sdk) contém exemplos escritos em Swift e Objective-C para iOS e Mac. Clique em um link para ver as instruções de instalação de cada exemplo:

* [Reconhecer uma fala de um microfone em Objective-C no macOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/objectivec/macos/from-microphone)
* [Reconhecer uma fala em Swift no macOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/swift/macos/from-microphone)
* [Reconhecer uma fala em Objective-C no iOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/objectivec/ios/from-microphone)
* [Reconhecer uma fala em Swift no iOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/swift/ios/from-microphone)
* [Exemplos adicionais para Objective-C no iOS](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/objective-c/ios)

Também fornecemos uma [Referência de SDK de Fala para Objective-C](https://docs.microsoft.com/objectivec/cognitive-services/speech/) online.



